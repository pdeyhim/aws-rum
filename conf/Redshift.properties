schemaVersion=1
# KinesisConnector Application Settings
appName = kinesisToRedshiftBasic
retryLimit = 3
# 1MB = 1024*1024 = 1048756
bufferSizeByteLimit = 1048576 
bufferRecordCountLimit = 2

# Redshift parameters for KinesisConnector
redshiftDataTable = kinesistable
redshiftEndpoint = https\://redshift.us-east-1.amazonaws.com
redshiftUsername = admin
redshiftPassword = Sepas!23456
# URL is optional if automatically creating the cluster
redshiftURL = jdbc:postgresql://kinesiscluster.cinbgjxflxxk.us-east-1.redshift.amazonaws.com:5439/kinesisdatabase?tcpKeepAlive=true	
redshiftDataDelimiter = ,

## Read our data schema from S3
dataJsonSchemaS3Key=awsrum/schema.json
dataJsonSchemaS3Bucket=parvizawstest

# Optional Redshift parameters for automatically creating the cluster
createRedshiftCluster = false
redshiftClusterIdentifier = kinesisCluster
redshiftDatabaseName = kinesisdatabase
# dw.hs1.xlarge or dw.hs1.8xlarge
redshiftClusterType = dw.hs1.xlarge
redshiftNumberOfNodes = 2

# Optional Redshift parameters for automatically creating the data table
createRedshiftDataTable = true

# S3 parameters for KinesisConnector
s3Bucket = parvizkinesis
s3Endpoint = https\://s3.amazonaws.com

# Optional S3 parameters for automatically creating the bucket
createS3Bucket = false

# Kinesis parameters for KinesisConnector
kinesisEndpoint = https\://kinesis.us-east-1.amazonaws.com
kinesisInputStream = myFirstStream

# Optional Kinesis parameters for automatically creating the stream
createKinesisInputStream = false
createKinesisOutputStream = false
kinesisInputStreamShardCount = 2
kinesisOutputStreamShardCount = 2

dynamoDBDataTableName=
dynamoDBKey=
dynamoDBRangeKey=
